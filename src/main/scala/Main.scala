// import org.apache.spark.sql.SQLContext
object Main extends App {
/*  def main(args: Array[String]): Unit = {
    //val conf = new SparkConf().setMaster("local[*]")
    println("number of arguments passed" + args.length)
    //sc.parallelize([3,4,5]).flatMap(lambda x: [x, x*x]).collect()
    println("Hello world!")
  }*/
println("Heres another one")
  def fileLoad ():
  Unit = {
  }
}